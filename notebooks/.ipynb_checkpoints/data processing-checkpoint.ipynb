{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../twitter_nlp/data/annotated/wnut16/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dev_2015',\n",
       " 'striptypes.py',\n",
       " 'glove.840B.300d.wnut_filtered.txt',\n",
       " 'test_notypes',\n",
       " 'train_notypes',\n",
       " 'dev_2015_notypes',\n",
       " 'test',\n",
       " 'dev_notypes',\n",
       " 'glove_wnut_filtered.200d.txt',\n",
       " 'train',\n",
       " 'dev']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3850\n"
     ]
    }
   ],
   "source": [
    "\" to create json out of original data\"\n",
    "\n",
    "filename = 'test'\n",
    "count = 0\n",
    "sentences = []\n",
    "sentence, ids = [], []\n",
    "with open(data_dir + filename, 'r') as fp:\n",
    "    for line in fp:\n",
    "        if line != '\\n':\n",
    "            info = line.strip().split('\\t')\n",
    "            sentence.append(info[0])\n",
    "            ids.append(info[1])\n",
    "        else:\n",
    "            sentences.append({'idx': count,\n",
    "                              'example': sentence,\n",
    "                             'label':ids})\n",
    "            sentence,ids = [],[]\n",
    "            count += 1\n",
    "print(count)\n",
    "\n",
    "with open(f'../{filename}.json', 'w') as fout:\n",
    "    json.dump(sentences , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "filename = 'train'\n",
    "with open(f'../{filename}.json', \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "labeldict = dict()\n",
    "for d in data:\n",
    "    \n",
    "    for l in d['label']:\n",
    "        if l not in labeldict:\n",
    "            labeldict[l] = 1\n",
    "        else:\n",
    "            labeldict[l] += 1\n",
    "print(len(labeldict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Distribution\n",
    "## 21 classes\n",
    "\n",
    "```\n",
    "train : {'O': 44007, 'B-geo-loc': 276, 'B-facility': 104, 'I-facility': 105, 'B-movie': 34, 'I-movie': 46, 'B-company': 171, 'B-product': 97, 'B-person': 449, 'B-other': 225, 'I-other': 320, 'B-sportsteam': 51, 'I-sportsteam': 23, 'I-product': 80, 'I-company': 36, 'I-person': 215, 'I-geo-loc': 49, 'B-tvshow': 34, 'B-musicartist': 55, 'I-musicartist': 61, 'I-tvshow': 31}\n",
    "\n",
    "dev : {'O': 15133, 'B-other': 132, 'I-other': 97, 'B-geo-loc': 116, 'I-geo-loc': 42, 'B-product': 37, 'I-product': 121, 'B-facility': 38, 'I-facility': 39, 'B-company': 39, 'I-company': 10, 'B-person': 171, 'I-person': 95, 'B-sportsteam': 70, 'B-musicartist': 41, 'I-musicartist': 35, 'I-sportsteam': 13, 'B-movie': 15, 'I-movie': 15, 'B-tvshow': 2}\n",
    "\n",
    "test : {'B-other': 584, 'I-other': 556, 'O': 55953, 'B-movie': 34, 'B-person': 482, 'I-person': 300, 'B-geo-loc': 882, 'B-company': 621, 'I-company': 265, 'B-product': 246, 'I-product': 500, 'B-musicartist': 191, 'I-musicartist': 140, 'B-sportsteam': 147, 'B-facility': 253, 'I-facility': 366, 'I-geo-loc': 219, 'I-movie': 48, 'I-sportsteam': 48, 'B-tvshow': 33, 'I-tvshow': 40}     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* https://github.com/aritter/twitter_nlp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
